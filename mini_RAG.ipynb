{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfDlUnlaH4PiwN+FzM+/rq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clingala/Mini-RAG-Chatbot/blob/main/mini_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrghLaRLHHrA"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain chromadb pypdf sentence-transformers openai tiktoken\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.1.16 chromadb==0.4.24 pypdf sentence-transformers\n"
      ],
      "metadata": {
        "id": "GG8BpXpzHu7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y opentelemetry-sdk opentelemetry-proto opentelemetry-exporter-otlp-proto-http\n"
      ],
      "metadata": {
        "id": "RTbYbWFKIIWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f209797f"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "!pip uninstall -y numpy packaging\n",
        "!pip install numpy==1.26.4 packaging==23.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03b506d4"
      },
      "source": [
        "import chromadb\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6a509d8"
      },
      "source": [
        "# Initialize an embedding function\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a75309f"
      },
      "source": [
        "# Initialize Chroma client (in-memory by default)\n",
        "chroma_client = chromadb.Client()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6600552"
      },
      "source": [
        "# Create a Chroma vector store. If a collection with the given name already exists, it will be loaded.\n",
        "vectorstore = Chroma(client=chroma_client, collection_name=\"my_documents\", embedding_function=embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5959fa58"
      },
      "source": [
        "!pip uninstall -y opentelemetry-sdk opentelemetry-proto opentelemetry-exporter-otlp-proto-http"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "langchain-community \\\n",
        "langchain-core \\\n",
        "chromadb \\\n",
        "pypdf \\\n",
        "sentence-transformers\n"
      ],
      "metadata": {
        "id": "z5gQirhlJ_sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import chromadb\n",
        "import sentence_transformers\n",
        "\n",
        "print(\"Environment ready.\")\n"
      ],
      "metadata": {
        "id": "n5UEd9TKKMVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "cPtis8PMKhlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=150\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(\"Total chunks:\", len(chunks))\n"
      ],
      "metadata": {
        "id": "XjMb4PSgLrIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "8hvuuCdhNDgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embedding_model\n",
        ")\n"
      ],
      "metadata": {
        "id": "2AQwWn8VSl54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the main contribution of this paper?\"\n",
        "\n",
        "docs = vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"\\n--- Chunk {i+1} ---\\n\")\n",
        "    print(doc.page_content[:500])\n"
      ],
      "metadata": {
        "id": "y_40ZpBiSt8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API Key: \")\n"
      ],
      "metadata": {
        "id": "2LWwE_bLS2Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=vectorstore.as_retriever()\n",
        ")\n",
        "\n",
        "response = qa_chain.run(query)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "vlkrAU3dW6Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-groq"
      ],
      "metadata": {
        "id": "KhiLixfNZQtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y langchain langchain-core langchain-community langsmith langgraph langgraph-prebuilt langgraph-checkpoint\n"
      ],
      "metadata": {
        "id": "-tZIDfUtaoJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "langchain==0.2.14 \\\n",
        "langchain-community==0.2.12 \\\n",
        "langchain-core==0.2.43 \\\n",
        "langchain-groq \\\n",
        "chromadb \\\n",
        "pypdf \\\n",
        "sentence-transformers\n"
      ],
      "metadata": {
        "id": "p0HVQFDgatJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import langchain_core\n",
        "print(\"Stable environment ready\")\n"
      ],
      "metadata": {
        "id": "-_ib2hdxbLSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y \\\n",
        "langchain \\\n",
        "langchain-core \\\n",
        "langchain-community \\\n",
        "langchain-openai \\\n",
        "langchain-groq \\\n",
        "langsmith \\\n",
        "langgraph \\\n",
        "langgraph-prebuilt \\\n",
        "langgraph-checkpoint\n"
      ],
      "metadata": {
        "id": "3-m9szfTbll8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \\\n",
        "langchain==0.2.14 \\\n",
        "langchain-core==0.2.43 \\\n",
        "langchain-community==0.2.12 \\\n",
        "langchain-groq==0.1.6 \\\n",
        "chromadb==0.4.24 \\\n",
        "pypdf \\\n",
        "sentence-transformers\n"
      ],
      "metadata": {
        "id": "e27wQZI-brIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import langchain_core\n",
        "import langchain_community\n",
        "\n",
        "print(\"LangChain fixed and ready âœ…\")\n"
      ],
      "metadata": {
        "id": "cBDpv6izb0Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "PoGOddHvcrrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=150\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(\"Total chunks:\", len(chunks))\n"
      ],
      "metadata": {
        "id": "3dsUTdiVcyhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(chunks))\n",
        "print(len(chunks))\n",
        "print(chunks[0].metadata)\n",
        "print(chunks[0].page_content[:300])\n"
      ],
      "metadata": {
        "id": "O8wRgEEPc6Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "\n",
        "# Test embedding works\n",
        "test_vec = embedding_model.embed_query(\"test sentence\")\n",
        "print(\"Embedding size:\", len(test_vec))\n"
      ],
      "metadata": {
        "id": "Xpl4LzIJdLIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embedding_model\n",
        ")\n",
        "\n",
        "print(\"Vectorstore created successfully\")\n"
      ],
      "metadata": {
        "id": "V0ZHCqZ_dT4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the main contribution of this paper?\"\n",
        "\n",
        "docs = vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "print(\"Retrieved:\", len(docs), \"documents\")\n",
        "print(docs[0].metadata)\n",
        "print(docs[0].page_content[:400])\n"
      ],
      "metadata": {
        "id": "Q3cciegIdZBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter Groq API Key: \")\n"
      ],
      "metadata": {
        "id": "xHniQbN1dcH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model_name=\"mixtral-8x7b-32768\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oyw7c8I8dkcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "models = client.models.list()\n",
        "for m in models.data:\n",
        "    print(m.id)\n"
      ],
      "metadata": {
        "id": "Bmg7Tt8_eNPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model_name=\"llama-3.1-8b-instant\",\n",
        "    temperature=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "DRl45tYseWQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "models = client.models.list()\n",
        "\n",
        "for m in models.data:\n",
        "    print(m.id)\n"
      ],
      "metadata": {
        "id": "XcmEpnk_el2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
        ")\n",
        "\n",
        "print(\"QA chain recreated successfully\")\n"
      ],
      "metadata": {
        "id": "I0YfOwnseolm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_chain.invoke({\"query\": query})\n",
        "print(result[\"result\"])\n"
      ],
      "metadata": {
        "id": "Ryg9FJmye3xD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "id": "P_eeMeFylb09"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}